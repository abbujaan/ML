{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-20T16:12:01.954470Z","iopub.execute_input":"2022-11-20T16:12:01.954881Z","iopub.status.idle":"2022-11-20T16:12:01.979533Z","shell.execute_reply.started":"2022-11-20T16:12:01.954847Z","shell.execute_reply":"2022-11-20T16:12:01.978208Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"/kaggle/input/pima-indians-diabetes-dataset/pima-indians-diabetes.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# import pandas as pd\ndata=pd.read_csv('/kaggle/input/pima-indians-diabetes-dataset/pima-indians-diabetes.csv)\ndata","metadata":{"execution":{"iopub.status.busy":"2022-11-20T15:39:29.224431Z","iopub.execute_input":"2022-11-20T15:39:29.224922Z","iopub.status.idle":"2022-11-20T15:39:29.252684Z","shell.execute_reply.started":"2022-11-20T15:39:29.224818Z","shell.execute_reply":"2022-11-20T15:39:29.251227Z"}}},{"cell_type":"code","source":"import pandas as pd\nfrom keras.models import Sequential\nfrom keras.layers import Dense\ndata=pd.read_csv('/kaggle/input/pima-indians-diabetes-dataset/pima-indians-diabetes.csv')\ndata","metadata":{"execution":{"iopub.status.busy":"2022-11-20T16:12:01.981598Z","iopub.execute_input":"2022-11-20T16:12:01.982229Z","iopub.status.idle":"2022-11-20T16:12:02.006977Z","shell.execute_reply.started":"2022-11-20T16:12:01.982196Z","shell.execute_reply":"2022-11-20T16:12:02.006151Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"      6  148  72  35    0  33.6  0.627  50  1\n0     1   85  66  29    0  26.6  0.351  31  0\n1     8  183  64   0    0  23.3  0.672  32  1\n2     1   89  66  23   94  28.1  0.167  21  0\n3     0  137  40  35  168  43.1  2.288  33  1\n4     5  116  74   0    0  25.6  0.201  30  0\n..   ..  ...  ..  ..  ...   ...    ...  .. ..\n762  10  101  76  48  180  32.9  0.171  63  0\n763   2  122  70  27    0  36.8  0.340  27  0\n764   5  121  72  23  112  26.2  0.245  30  0\n765   1  126  60   0    0  30.1  0.349  47  1\n766   1   93  70  31    0  30.4  0.315  23  0\n\n[767 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>6</th>\n      <th>148</th>\n      <th>72</th>\n      <th>35</th>\n      <th>0</th>\n      <th>33.6</th>\n      <th>0.627</th>\n      <th>50</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>116</td>\n      <td>74</td>\n      <td>0</td>\n      <td>0</td>\n      <td>25.6</td>\n      <td>0.201</td>\n      <td>30</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>762</th>\n      <td>10</td>\n      <td>101</td>\n      <td>76</td>\n      <td>48</td>\n      <td>180</td>\n      <td>32.9</td>\n      <td>0.171</td>\n      <td>63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>2</td>\n      <td>122</td>\n      <td>70</td>\n      <td>27</td>\n      <td>0</td>\n      <td>36.8</td>\n      <td>0.340</td>\n      <td>27</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>5</td>\n      <td>121</td>\n      <td>72</td>\n      <td>23</td>\n      <td>112</td>\n      <td>26.2</td>\n      <td>0.245</td>\n      <td>30</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>1</td>\n      <td>126</td>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.1</td>\n      <td>0.349</td>\n      <td>47</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>766</th>\n      <td>1</td>\n      <td>93</td>\n      <td>70</td>\n      <td>31</td>\n      <td>0</td>\n      <td>30.4</td>\n      <td>0.315</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>767 rows Ã— 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"x=data.iloc[:,0:-1].values\ny=data.iloc[:,8].values","metadata":{"execution":{"iopub.status.busy":"2022-11-20T16:12:02.008350Z","iopub.execute_input":"2022-11-20T16:12:02.009050Z","iopub.status.idle":"2022-11-20T16:12:02.014201Z","shell.execute_reply.started":"2022-11-20T16:12:02.009016Z","shell.execute_reply":"2022-11-20T16:12:02.013109Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(12, input_dim=8, activation='relu'))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n# compile model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n# fitting of model\nmodel.fit(x, y, epochs=200, batch_size=10)\n_, accuracy = model.evaluate(x, y)\nprint('Accuracy: %.2f' % (accuracy*100))\n","metadata":{"execution":{"iopub.status.busy":"2022-11-20T16:13:13.577052Z","iopub.execute_input":"2022-11-20T16:13:13.577439Z","iopub.status.idle":"2022-11-20T16:13:45.822442Z","shell.execute_reply.started":"2022-11-20T16:13:13.577407Z","shell.execute_reply":"2022-11-20T16:13:45.820786Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Epoch 1/200\n77/77 [==============================] - 1s 2ms/step - loss: 1.4660 - accuracy: 0.5437\nEpoch 2/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.8881 - accuracy: 0.6375\nEpoch 3/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.7883 - accuracy: 0.6219\nEpoch 4/200\n77/77 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.6558\nEpoch 5/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.6728\nEpoch 6/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.6754\nEpoch 7/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6923\nEpoch 8/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.6714\nEpoch 9/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.6078 - accuracy: 0.6884\nEpoch 10/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.6962\nEpoch 11/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.6988\nEpoch 12/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.6962\nEpoch 13/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.6988\nEpoch 14/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.6988\nEpoch 15/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.6923\nEpoch 16/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.7066\nEpoch 17/200\n77/77 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.7158\nEpoch 18/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7145\nEpoch 19/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7066\nEpoch 20/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7197\nEpoch 21/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.6949\nEpoch 22/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7119\nEpoch 23/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7040\nEpoch 24/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7093\nEpoch 25/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7093\nEpoch 26/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7301\nEpoch 27/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7184\nEpoch 28/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7184\nEpoch 29/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7184\nEpoch 30/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.7197\nEpoch 31/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7314\nEpoch 32/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7158\nEpoch 33/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7275\nEpoch 34/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7236\nEpoch 35/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7314\nEpoch 36/200\n77/77 [==============================] - 0s 1ms/step - loss: 0.5364 - accuracy: 0.7419\nEpoch 37/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7327\nEpoch 38/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7327\nEpoch 39/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7197\nEpoch 40/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7314\nEpoch 41/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7171\nEpoch 42/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7366\nEpoch 43/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7301\nEpoch 44/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7145\nEpoch 45/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7445\nEpoch 46/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7432\nEpoch 47/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7314\nEpoch 48/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7392\nEpoch 49/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7405\nEpoch 50/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7510\nEpoch 51/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7419\nEpoch 52/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7536\nEpoch 53/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7327\nEpoch 54/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7405\nEpoch 55/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7471\nEpoch 56/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7484\nEpoch 57/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7314\nEpoch 58/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7327\nEpoch 59/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7405\nEpoch 60/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7353\nEpoch 61/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7353\nEpoch 62/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7497\nEpoch 63/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7405\nEpoch 64/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7340\nEpoch 65/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7523\nEpoch 66/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7445\nEpoch 67/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7366\nEpoch 68/200\n77/77 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7340\nEpoch 69/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7445\nEpoch 70/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7484\nEpoch 71/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7392\nEpoch 72/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7614\nEpoch 73/200\n77/77 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7458\nEpoch 74/200\n77/77 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.7458\nEpoch 75/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7471\nEpoch 76/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7549\nEpoch 77/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7471\nEpoch 78/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7458\nEpoch 79/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7692\nEpoch 80/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7497\nEpoch 81/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7445\nEpoch 82/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7601\nEpoch 83/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7523\nEpoch 84/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7458\nEpoch 85/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7718\nEpoch 86/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7614\nEpoch 87/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7471\nEpoch 88/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7640\nEpoch 89/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7562\nEpoch 90/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7523\nEpoch 91/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7432\nEpoch 92/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7601\nEpoch 93/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7536\nEpoch 94/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7731\nEpoch 95/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7679\nEpoch 96/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7666\nEpoch 97/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7640\nEpoch 98/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7705\nEpoch 99/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7653\nEpoch 100/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7614\nEpoch 101/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7627\nEpoch 102/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7588\nEpoch 103/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7588\nEpoch 104/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7627\nEpoch 105/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7575\nEpoch 106/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7653\nEpoch 107/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7627\nEpoch 108/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7666\nEpoch 109/200\n77/77 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7679\nEpoch 110/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7562\nEpoch 111/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7731\nEpoch 112/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7432\nEpoch 113/200\n77/77 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7705\nEpoch 114/200\n77/77 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7692\nEpoch 115/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7679\nEpoch 116/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7836\nEpoch 117/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7757\nEpoch 118/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7692\nEpoch 119/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7510\nEpoch 120/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7862\nEpoch 121/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7705\nEpoch 122/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7692\nEpoch 123/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7849\nEpoch 124/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7744\nEpoch 125/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7692\nEpoch 126/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7679\nEpoch 127/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7588\nEpoch 128/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7692\nEpoch 129/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7823\nEpoch 130/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7705\nEpoch 131/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7692\nEpoch 132/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7836\nEpoch 133/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7810\nEpoch 134/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7771\nEpoch 135/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7836\nEpoch 136/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7875\nEpoch 137/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7810\nEpoch 138/200\n77/77 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7901\nEpoch 139/200\n77/77 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7914\nEpoch 140/200\n77/77 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7692\nEpoch 141/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7914\nEpoch 142/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7810\nEpoch 143/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.8070\nEpoch 144/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7836\nEpoch 145/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7940\nEpoch 146/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7901\nEpoch 147/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7888\nEpoch 148/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7849\nEpoch 149/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7914\nEpoch 150/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7862\nEpoch 151/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7731\nEpoch 152/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7875\nEpoch 153/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7927\nEpoch 154/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7797\nEpoch 155/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7875\nEpoch 156/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7875\nEpoch 157/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7888\nEpoch 158/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7862\nEpoch 159/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7979\nEpoch 160/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7757\nEpoch 161/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7875\nEpoch 162/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7888\nEpoch 163/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7914\nEpoch 164/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8031\nEpoch 165/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7940\nEpoch 166/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7823\nEpoch 167/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7979\nEpoch 168/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7875\nEpoch 169/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8031\nEpoch 170/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7953\nEpoch 171/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7979\nEpoch 172/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7862\nEpoch 173/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7836\nEpoch 174/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7927\nEpoch 175/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7862\nEpoch 176/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7875\nEpoch 177/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7927\nEpoch 178/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7836\nEpoch 179/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7862\nEpoch 180/200\n77/77 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7823\nEpoch 181/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7914\nEpoch 182/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7862\nEpoch 183/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7979\nEpoch 184/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8018\nEpoch 185/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7992\nEpoch 186/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7966\nEpoch 187/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7875\nEpoch 188/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7823\nEpoch 189/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7888\nEpoch 190/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7927\nEpoch 191/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8018\nEpoch 192/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7914\nEpoch 193/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8057\nEpoch 194/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7927\nEpoch 195/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7940\nEpoch 196/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7979\nEpoch 197/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7927\nEpoch 198/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7992\nEpoch 199/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8070\nEpoch 200/200\n77/77 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8018\n24/24 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7966\nAccuracy: 79.66\n","output_type":"stream"}]},{"cell_type":"code","source":"_, accuracy = model.evaluate(x, y)\nprint('Accuracy: %.2f' % (accuracy*100))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-20T16:13:51.185576Z","iopub.execute_input":"2022-11-20T16:13:51.186031Z","iopub.status.idle":"2022-11-20T16:13:51.292989Z","shell.execute_reply.started":"2022-11-20T16:13:51.185972Z","shell.execute_reply":"2022-11-20T16:13:51.291213Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"24/24 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7966\nAccuracy: 79.66\nModel: \"sequential_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_21 (Dense)             (None, 12)                108       \n_________________________________________________________________\ndense_22 (Dense)             (None, 8)                 104       \n_________________________________________________________________\ndense_23 (Dense)             (None, 1)                 9         \n=================================================================\nTotal params: 221\nTrainable params: 221\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip3 install ann_visualizer\n!pip install graphviz\n","metadata":{"execution":{"iopub.status.busy":"2022-11-20T16:14:46.634264Z","iopub.execute_input":"2022-11-20T16:14:46.635197Z","iopub.status.idle":"2022-11-20T16:16:05.332594Z","shell.execute_reply.started":"2022-11-20T16:14:46.635140Z","shell.execute_reply":"2022-11-20T16:16:05.331117Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f9c186735d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/ann-visualizer/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f9c186a6150>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/ann-visualizer/\u001b[0m\u001b[33m\n\u001b[0m^C\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.7/site-packages (0.8.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m^C\n","output_type":"stream"}]},{"cell_type":"code","source":"from ann_visualizer.visualize import ann_viz;\nann_viz(model, title=\"Artificial Neural Network\")","metadata":{"execution":{"iopub.status.busy":"2022-11-20T16:16:05.334677Z","iopub.execute_input":"2022-11-20T16:16:05.335047Z","iopub.status.idle":"2022-11-20T16:16:05.364257Z","shell.execute_reply.started":"2022-11-20T16:16:05.334985Z","shell.execute_reply":"2022-11-20T16:16:05.362527Z"},"trusted":true},"execution_count":40,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1383417041.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mann_visualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mann_viz\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mann_viz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Artificial Neural Network\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ann_visualizer'"],"ename":"ModuleNotFoundError","evalue":"No module named 'ann_visualizer'","output_type":"error"}]}]}